\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}\uppercase {Experiments}}{54}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Data Statistics}{54}{section.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Label Distribution\relax }}{54}{figure.caption.53}}
\newlabel{fig:srldistribution}{{5.1}{54}{Label Distribution\relax }{figure.caption.53}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Experiment Scenario}{54}{section.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Scenario 1: Feature Selection}{55}{subsection.5.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Results (in \%) of Feature Selection Scenario\relax }}{55}{table.caption.54}}
\newlabel{tab:feature_scenario}{{5.1}{55}{Results (in \%) of Feature Selection Scenario\relax }{table.caption.54}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Precision, Recall, F1 scores (in \%) of each label for scenario WE\relax }}{56}{table.caption.55}}
\newlabel{tab:ex11srl}{{5.2}{56}{Precision, Recall, F1 scores (in \%) of each label for scenario WE\relax }{table.caption.55}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Misprediction example of \textsc  {Greet}\nobreakspace  {}when using only WE as the feature\relax }}{56}{table.caption.56}}
\newlabel{tab:contohgreetagent}{{5.3}{56}{Misprediction example of \greet ~when using only WE as the feature\relax }{table.caption.56}{}}
\citation{carreras2005introduction}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Correct prediction example of \textsc  {Greet}when using WE + NW as the features\relax }}{57}{table.caption.57}}
\newlabel{tab:contohgreetagenttrue}{{5.4}{57}{Correct prediction example of \greet when using WE + NW as the features\relax }{table.caption.57}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces Misprediction example of \textsc  {Time}\nobreakspace  {}when using WE as the feature\relax }}{57}{table.caption.58}}
\newlabel{tab:contohwaktufalse}{{5.5}{57}{Misprediction example of \timesrl ~when using WE as the feature\relax }{table.caption.58}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.6}{\ignorespaces Precision, Recall, F1 scores (in \%) of each label for scenario WE and WE + POS\relax }}{58}{table.caption.59}}
\newlabel{tab:wevswepos}{{5.6}{58}{Precision, Recall, F1 scores (in \%) of each label for scenario WE and WE + POS\relax }{table.caption.59}{}}
\citation{zhou2015end}
\@writefile{lot}{\contentsline {table}{\numberline {5.7}{\ignorespaces Correct prediction example of \textsc  {Time}\nobreakspace  {}when using WE + POS as the features\relax }}{59}{table.caption.60}}
\newlabel{tab:timetrue}{{5.7}{59}{Correct prediction example of \timesrl ~when using WE + POS as the features\relax }{table.caption.60}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Scenario 2: Model Selection}{59}{subsection.5.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2.1}Scenario 2a: LSTM, BLSTM and DBLSTM}{59}{subsubsection.5.2.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {5.8}{\ignorespaces F1 scores (in \%) of WE + POS and WE + POS + NW when using vanilla LSTM (LSTM), BLSTM, and Deep BLSTM (DBLSTM) architectures.\relax }}{59}{table.caption.61}}
\newlabel{tab:modelselection1}{{5.8}{59}{F1 scores (in \%) of WE + POS and WE + POS + NW when using vanilla LSTM (LSTM), BLSTM, and Deep BLSTM (DBLSTM) architectures.\relax }{table.caption.61}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.9}{\ignorespaces Result comparison between using vanilla LSTM and DBLSTM architecture when WE + POS features are used.\relax }}{60}{table.caption.62}}
\newlabel{tab:lstmdblstm}{{5.9}{60}{Result comparison between using vanilla LSTM and DBLSTM architecture when WE + POS features are used.\relax }{table.caption.62}{}}
\citation{zhou2015end}
\citation{he2017deep}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2.2}Scenario 2b: DBLSTM, DBLSTM-Zhou, and DBLSTM-Highway}{61}{subsubsection.5.2.2.2}}
\@writefile{lot}{\contentsline {table}{\numberline {5.10}{\ignorespaces Precision, Recall, and F1 scores (in \%) of Deep BLSTM (DBLSTM), DBLSTM-Zhou, and DBLSTM-Highway\relax }}{61}{table.caption.63}}
\newlabel{tab:modelselection2}{{5.10}{61}{Precision, Recall, and F1 scores (in \%) of Deep BLSTM (DBLSTM), DBLSTM-Zhou, and DBLSTM-Highway\relax }{table.caption.63}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.11}{\ignorespaces Result comparison between using DBLSTM and DBLSTM-Highway architecture for every semantic role\relax }}{61}{table.caption.64}}
\newlabel{tab:dblstmdblstmhighway}{{5.11}{61}{Result comparison between using DBLSTM and DBLSTM-Highway architecture for every semantic role\relax }{table.caption.64}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2.3}Scenario 2c: CNN Layer}{62}{subsubsection.5.2.2.3}}
\@writefile{lot}{\contentsline {table}{\numberline {5.12}{\ignorespaces The precision, recall, and F1 scores (in \%) of the DBLSTM architectures with and without CNN layer.\relax }}{62}{table.caption.65}}
\newlabel{tab:modelselection3}{{5.12}{62}{The precision, recall, and F1 scores (in \%) of the DBLSTM architectures with and without CNN layer.\relax }{table.caption.65}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2.4}Scenario 2d: Attention Layer}{62}{subsubsection.5.2.2.4}}
\@writefile{lot}{\contentsline {table}{\numberline {5.13}{\ignorespaces The precision, recall, and F1 scores (in \%) of the DBLSTM architectures with and without attention layer.\relax }}{63}{table.caption.66}}
\newlabel{tab:modelselection4}{{5.13}{63}{The precision, recall, and F1 scores (in \%) of the DBLSTM architectures with and without attention layer.\relax }{table.caption.66}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.14}{\ignorespaces Result comparison between using DBLSTM-Highway and DBLSTM-Highway + Attention architecture for every semantic role\relax }}{63}{table.caption.67}}
\newlabel{tab:dblstmhighwayattention}{{5.14}{63}{Result comparison between using DBLSTM-Highway and DBLSTM-Highway + Attention architecture for every semantic role\relax }{table.caption.67}{}}
\@setckpt{bab5}{
\setcounter{page}{65}
\setcounter{equation}{0}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{2}
\setcounter{subsection}{2}
\setcounter{subsubsection}{4}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{1}
\setcounter{table}{14}
\setcounter{parentequation}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{AlgoLine}{8}
\setcounter{algocfline}{12}
\setcounter{algocfproc}{12}
\setcounter{algocf}{0}
\setcounter{NAT@ctr}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{AM@survey}{0}
\setcounter{float@type}{8}
\setcounter{lstnumber}{1}
\setcounter{FancyVerbLine}{0}
\setcounter{Item}{51}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{77}
\setcounter{lstlisting}{0}
\setcounter{section@level}{3}
}
