\BOOKMARK [0][-]{section*.2}{HALAMAN JUDUL}{}% 1
\BOOKMARK [0][-]{section*.4}{LEMBAR PERNYATAAN ORISINALITAS}{}% 2
\BOOKMARK [0][-]{section*.6}{LEMBAR PENGESAHAN}{}% 3
\BOOKMARK [0][-]{section*.8}{Remarks}{}% 4
\BOOKMARK [0][-]{section*.10}{LEMBAR PERSETUJUAN PUBLIKASI ILMIAH}{}% 5
\BOOKMARK [0][-]{section*.12}{ABSTRAK}{}% 6
\BOOKMARK [0][-]{chapter*.15}{Daftar Isi}{}% 7
\BOOKMARK [0][-]{chapter*.16}{Daftar Gambar}{}% 8
\BOOKMARK [0][-]{chapter*.17}{Daftar Tabel}{}% 9
\BOOKMARK [0][-]{chapter*.18}{Daftar Kode}{}% 10
\BOOKMARK [0][-]{chapter.1}{1 Introduction}{}% 11
\BOOKMARK [1][-]{section.1.1}{1.1 Background}{chapter.1}% 12
\BOOKMARK [1][-]{section.1.2}{1.2 Problem Statement}{chapter.1}% 13
\BOOKMARK [1][-]{section.1.3}{1.3 Objectives and Contributions}{chapter.1}% 14
\BOOKMARK [1][-]{section.1.4}{1.4 Methodology}{chapter.1}% 15
\BOOKMARK [1][-]{section.1.5}{1.5 Scope}{chapter.1}% 16
\BOOKMARK [1][-]{section.1.6}{1.6 Organization}{chapter.1}% 17
\BOOKMARK [0][-]{chapter.2}{2 Literature Review}{}% 18
\BOOKMARK [1][-]{section.2.1}{2.1 Language Models}{chapter.2}% 19
\BOOKMARK [2][-]{subsection.2.1.1}{2.1.1 Part-of-Speech Tag \(POS Tag\)}{section.2.1}% 20
\BOOKMARK [2][-]{subsection.2.1.2}{2.1.2 Word Embedding}{section.2.1}% 21
\BOOKMARK [1][-]{section.2.2}{2.2 Deep Learning}{chapter.2}% 22
\BOOKMARK [2][-]{subsection.2.2.1}{2.2.1 Recurrent Neural Networks}{section.2.2}% 23
\BOOKMARK [2][-]{subsection.2.2.2}{2.2.2 Long Short-Term Memories}{section.2.2}% 24
\BOOKMARK [1][-]{section.2.3}{2.3 Semantic Role Labeling}{chapter.2}% 25
\BOOKMARK [2][-]{subsection.2.3.1}{2.3.1 Semantic Roles}{section.2.3}% 26
\BOOKMARK [2][-]{subsection.2.3.2}{2.3.2 Annotation Corpus}{section.2.3}% 27
\BOOKMARK [3][-]{subsubsection.2.3.2.1}{2.3.2.1 Proposition Bank}{subsection.2.3.2}% 28
\BOOKMARK [3][-]{subsubsection.2.3.2.2}{2.3.2.2 FrameNet}{subsection.2.3.2}% 29
\BOOKMARK [2][-]{subsection.2.3.3}{2.3.3 Problem Definitions}{section.2.3}% 30
\BOOKMARK [2][-]{subsection.2.3.4}{2.3.4 Common Features for SRL}{section.2.3}% 31
\BOOKMARK [2][-]{subsection.2.3.5}{2.3.5 Historical Perspectives}{section.2.3}% 32
\BOOKMARK [0][-]{chapter.3}{3 Methodology}{}% 33
\BOOKMARK [1][-]{section.3.1}{3.1 Pipeline}{chapter.3}% 34
\BOOKMARK [1][-]{section.3.2}{3.2 Data Gathering}{chapter.3}% 35
\BOOKMARK [1][-]{section.3.3}{3.3 Data Pre-Processing}{chapter.3}% 36
\BOOKMARK [1][-]{section.3.4}{3.4 Data Annotation}{chapter.3}% 37
\BOOKMARK [1][-]{section.3.5}{3.5 Feature Extraction}{chapter.3}% 38
\BOOKMARK [2][-]{subsection.3.5.1}{3.5.1 Word Embedding}{section.3.5}% 39
\BOOKMARK [2][-]{subsection.3.5.2}{3.5.2 Part-of-Speech Tag \(POS Tag\)}{section.3.5}% 40
\BOOKMARK [2][-]{subsection.3.5.3}{3.5.3 Neighboring Word Embeddings}{section.3.5}% 41
\BOOKMARK [1][-]{section.3.6}{3.6 Model Architecture}{chapter.3}% 42
\BOOKMARK [2][-]{subsection.3.6.1}{3.6.1 Main Layers}{section.3.6}% 43
\BOOKMARK [3][-]{subsubsection.3.6.1.1}{3.6.1.1 Vanilla LSTM \(LSTM\)}{subsection.3.6.1}% 44
\BOOKMARK [3][-]{subsubsection.3.6.1.2}{3.6.1.2 Bi-Directional LSTM \(BLSTM\)}{subsection.3.6.1}% 45
\BOOKMARK [3][-]{subsubsection.3.6.1.3}{3.6.1.3 Deep BLSTM \(DBLSTM\)}{subsection.3.6.1}% 46
\BOOKMARK [3][-]{subsubsection.3.6.1.4}{3.6.1.4 Deep BLSTM-Zhou \(DBLSTM-Zhou\)}{subsection.3.6.1}% 47
\BOOKMARK [3][-]{subsubsection.3.6.1.5}{3.6.1.5 Deep BLSTM-Highway \(DBLSTM-Highway\)}{subsection.3.6.1}% 48
\BOOKMARK [2][-]{subsection.3.6.2}{3.6.2 Additional Layers}{section.3.6}% 49
\BOOKMARK [3][-]{subsubsection.3.6.2.1}{3.6.2.1 Convolutional Neural Networks \(CNN\)}{subsection.3.6.2}% 50
\BOOKMARK [3][-]{subsubsection.3.6.2.2}{3.6.2.2 Attention Mechanism}{subsection.3.6.2}% 51
\BOOKMARK [1][-]{section.3.7}{3.7 Experiment}{chapter.3}% 52
\BOOKMARK [1][-]{section.3.8}{3.8 Evaluation}{chapter.3}% 53
\BOOKMARK [0][-]{chapter.4}{4 Implementation}{}% 54
\BOOKMARK [1][-]{section.4.1}{4.1 Computer Specification}{chapter.4}% 55
\BOOKMARK [1][-]{section.4.2}{4.2 Data Annotation and Pre-processing}{chapter.4}% 56
\BOOKMARK [1][-]{section.4.3}{4.3 Model Development}{chapter.4}% 57
\BOOKMARK [2][-]{subsection.4.3.1}{4.3.1 Feature Extraction}{section.4.3}% 58
\BOOKMARK [3][-]{subsubsection.4.3.1.1}{4.3.1.1 Word Embedding}{subsection.4.3.1}% 59
\BOOKMARK [3][-]{subsubsection.4.3.1.2}{4.3.1.2 POS Tag}{subsection.4.3.1}% 60
\BOOKMARK [3][-]{subsubsection.4.3.1.3}{4.3.1.3 Neighboring Word Embeddings}{subsection.4.3.1}% 61
\BOOKMARK [2][-]{subsection.4.3.2}{4.3.2 Model Architecture}{section.4.3}% 62
\BOOKMARK [3][-]{subsubsection.4.3.2.1}{4.3.2.1 Vanilla LSTM \(LSTM\)}{subsection.4.3.2}% 63
\BOOKMARK [3][-]{subsubsection.4.3.2.2}{4.3.2.2 Bi-Directional LSTM \(BLSTM\)}{subsection.4.3.2}% 64
\BOOKMARK [3][-]{subsubsection.4.3.2.3}{4.3.2.3 CNN-BLSTM}{subsection.4.3.2}% 65
\BOOKMARK [3][-]{subsubsection.4.3.2.4}{4.3.2.4 Context-Aware BLSTM \(CA-BLSTM\)}{subsection.4.3.2}% 66
\BOOKMARK [1][-]{section.4.4}{4.4 Experiment}{chapter.4}% 67
\BOOKMARK [1][-]{section.4.5}{4.5 Evaluation}{chapter.4}% 68
\BOOKMARK [0][-]{chapter.5}{5 Experiments}{}% 69
\BOOKMARK [1][-]{section.5.1}{5.1 Data Statistics}{chapter.5}% 70
\BOOKMARK [1][-]{section.5.2}{5.2 Experiment Scenario}{chapter.5}% 71
\BOOKMARK [1][-]{section.5.3}{5.3 Scenario 1: Feature Selection}{chapter.5}% 72
\BOOKMARK [2][-]{subsection.5.3.1}{5.3.1 Scenario 2: Model Selection}{section.5.3}% 73
\BOOKMARK [3][-]{subsubsection.5.3.1.1}{5.3.1.1 Scenario 2a: LSTM, BLSTM and DBLSTM}{subsection.5.3.1}% 74
\BOOKMARK [3][-]{subsubsection.5.3.1.2}{5.3.1.2 Scenario 2b: DBLSTM, DBLSTM-Zhou, and DBLSTM-Highway}{subsection.5.3.1}% 75
\BOOKMARK [3][-]{subsubsection.5.3.1.3}{5.3.1.3 Scenario 2c: CNN Layer}{subsection.5.3.1}% 76
\BOOKMARK [3][-]{subsubsection.5.3.1.4}{5.3.1.4 Scenario 2d: Attention Layer}{subsection.5.3.1}% 77
\BOOKMARK [0][-]{chapter.6}{6 Conclusions}{}% 78
\BOOKMARK [1][-]{section.6.1}{6.1 Kesimpulan}{chapter.6}% 79
\BOOKMARK [1][-]{section.6.2}{6.2 Saran}{chapter.6}% 80
\BOOKMARK [0][-]{chapter*.62}{Daftar Referensi}{}% 81
\BOOKMARK [0][-]{section*.63}{LAMPIRAN}{}% 82
