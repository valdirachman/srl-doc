\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}\uppercase {Methodology}}{22}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{bab:tiga}{{3}{22}{\babTiga }{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Pipeline}{22}{section.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Methodology Pipeline\relax }}{23}{figure.caption.26}}
\newlabel{fig:pipeline}{{3.1}{23}{Methodology Pipeline\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Data Gathering}{23}{section.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Data Pre-Processing}{24}{section.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Data Annotation}{24}{section.3.4}}
\citation{saeed19972003}
\citation{dowty1991thematic}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Set of Semantic Roles for Conversational Language\relax }}{25}{table.caption.27}}
\newlabel{tab:semantic_roles}{{3.1}{25}{Set of Semantic Roles for Conversational Language\relax }{table.caption.27}{}}
\citation{collobert2011natural}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Set of Semantic Roles for Conversational Language\relax }}{27}{table.caption.28}}
\newlabel{tab:examplelabel}{{3.2}{27}{Set of Semantic Roles for Conversational Language\relax }{table.caption.28}{}}
\citation{zhou2015end}
\citation{collobert2011natural}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Feature Extraction}{28}{section.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Word Embedding}{28}{subsection.3.5.1}}
\citation{carreras2005introduction}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces An example of word embedding vector representation with dimension of 3\relax }}{29}{table.caption.29}}
\newlabel{tab:examplewe}{{3.3}{29}{An example of word embedding vector representation with dimension of 3\relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Part-of-Speech Tag (POS Tag)}{29}{subsection.3.5.2}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces An example of POS Tag feature and its respective one-hot-vector\relax }}{29}{table.caption.30}}
\newlabel{tab:examplepos}{{3.4}{29}{An example of POS Tag feature and its respective one-hot-vector\relax }{table.caption.30}{}}
\citation{zhou2015end}
\citation{hochreiter1997long}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Neighboring Word Embeddings}{30}{subsection.3.5.3}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces An example of neighboring word embedding vectors of every time step\relax }}{30}{table.caption.31}}
\newlabel{tab:examplenwe}{{3.5}{30}{An example of neighboring word embedding vectors of every time step\relax }{table.caption.31}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Model Architecture}{30}{section.3.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Main Layers}{31}{subsection.3.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1.1}Vanilla LSTM (LSTM)}{31}{subsubsection.3.6.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces An architecture of Context-Aware Bi-Directional Long Short Term Memories with total time step of 4\relax }}{31}{figure.caption.32}}
\newlabel{fig:olstm}{{3.2}{31}{An architecture of Context-Aware Bi-Directional Long Short Term Memories with total time step of 4\relax }{figure.caption.32}{}}
\newlabel{eq:lstm}{{3.2}{31}{Vanilla LSTM (LSTM)}{equation.3.6.2}{}}
\newlabel{eq:softmaxout}{{3.3}{31}{Vanilla LSTM (LSTM)}{equation.3.6.3}{}}
\citation{schuster1997bidirectional}
\citation{zhou2015end}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces An LSTM unit in time step $t$\relax }}{32}{figure.caption.33}}
\newlabel{fig:lstmunit}{{3.3}{32}{An LSTM unit in time step $t$\relax }{figure.caption.33}{}}
\newlabel{eq:lstmm}{{3.4}{32}{Vanilla LSTM (LSTM)}{equation.3.6.4}{}}
\newlabel{eq:lstmh}{{3.5}{32}{Vanilla LSTM (LSTM)}{equation.3.6.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1.2}Bi-Directional LSTM (BLSTM)}{33}{subsubsection.3.6.1.2}}
\newlabel{sec:blstm}{{3.6.1.2}{33}{Bi-Directional LSTM (BLSTM)}{subsubsection.3.6.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces An architecture of Context-Aware Bi-Directional Long Short Term Memories with total time step of 4\relax }}{33}{figure.caption.34}}
\newlabel{fig:bilstm}{{3.4}{33}{An architecture of Context-Aware Bi-Directional Long Short Term Memories with total time step of 4\relax }{figure.caption.34}{}}
\newlabel{eq:lstmforward}{{3.6}{33}{Bi-Directional LSTM (BLSTM)}{equation.3.6.6}{}}
\newlabel{eq:lstmbackward}{{3.7}{33}{Bi-Directional LSTM (BLSTM)}{equation.3.6.7}{}}
\newlabel{eq:lstm_concat}{{3.8}{33}{Bi-Directional LSTM (BLSTM)}{equation.3.6.8}{}}
\citation{zhou2015end}
\newlabel{eq:bilstm_softmax}{{3.9}{34}{Bi-Directional LSTM (BLSTM)}{equation.3.6.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1.3}Deep BLSTM (DBLSTM)}{34}{subsubsection.3.6.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces An architecture of Context-Aware Bi-Directional Long Short Term Memories with total time step of 4\relax }}{34}{figure.caption.35}}
\newlabel{fig:dblstm}{{3.5}{34}{An architecture of Context-Aware Bi-Directional Long Short Term Memories with total time step of 4\relax }{figure.caption.35}{}}
\citation{zhou2015end}
\citation{zhou2015end}
\newlabel{eq:lstmforward2}{{3.10}{35}{Deep BLSTM (DBLSTM)}{equation.3.6.10}{}}
\newlabel{eq:lstmbackward2}{{3.11}{35}{Deep BLSTM (DBLSTM)}{equation.3.6.11}{}}
\newlabel{eq:lstm_concat2}{{3.12}{35}{Deep BLSTM (DBLSTM)}{equation.3.6.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1.4}Deep BLSTM-Zhou (DBLSTM-Zhou)}{35}{subsubsection.3.6.1.4}}
\citation{he2017deep}
\citation{zhou2015end}
\citation{srivastava2015training}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces An architecture of Context-Aware Bi-Directional Long Short Term Memories with total time step of 4\relax }}{36}{figure.caption.36}}
\newlabel{fig:dblstmzhou}{{3.6}{36}{An architecture of Context-Aware Bi-Directional Long Short Term Memories with total time step of 4\relax }{figure.caption.36}{}}
\newlabel{eq:lstmforwardzhou1}{{3.13}{36}{Deep BLSTM-Zhou (DBLSTM-Zhou)}{equation.3.6.13}{}}
\newlabel{eq:lstmbackwardzhou1}{{3.14}{36}{Deep BLSTM-Zhou (DBLSTM-Zhou)}{equation.3.6.14}{}}
\newlabel{eq:lstmforwardzhou2}{{3.15}{36}{Deep BLSTM-Zhou (DBLSTM-Zhou)}{equation.3.6.15}{}}
\newlabel{eq:lstmbackwardzhou2}{{3.16}{36}{Deep BLSTM-Zhou (DBLSTM-Zhou)}{equation.3.6.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1.5}Deep BLSTM-Highway (DBLSTM-Highway)}{37}{subsubsection.3.6.1.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces An architecture of Context-Aware Bi-Directional Long Short Term Memories with total time step of 4\relax }}{37}{figure.caption.37}}
\newlabel{fig:dblstmhighway}{{3.7}{37}{An architecture of Context-Aware Bi-Directional Long Short Term Memories with total time step of 4\relax }{figure.caption.37}{}}
\newlabel{eq:forwardhighway1}{{3.17}{37}{Deep BLSTM-Highway (DBLSTM-Highway)}{equation.3.6.17}{}}
\newlabel{eq:backwardhighway1}{{3.18}{37}{Deep BLSTM-Highway (DBLSTM-Highway)}{equation.3.6.18}{}}
\newlabel{eq:forwardhighway2}{{3.21}{38}{Deep BLSTM-Highway (DBLSTM-Highway)}{equation.3.6.21}{}}
\newlabel{eq:backwardhighway2}{{3.24}{38}{Deep BLSTM-Highway (DBLSTM-Highway)}{equation.3.6.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Additional Layers}{38}{subsection.3.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2.1}Convolutional Neural Networks (CNN)}{38}{subsubsection.3.6.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces An architecture of adding CNN underneath the main layer with total time step of 4. The main layer is illustrated by the shaded architecture inside the rectangle. The main layer can be changed into any LSTM variants.\relax }}{39}{figure.caption.38}}
\newlabel{fig:cnndblstmhighway}{{3.8}{39}{An architecture of adding CNN underneath the main layer with total time step of 4. The main layer is illustrated by the shaded architecture inside the rectangle. The main layer can be changed into any LSTM variants.\relax }{figure.caption.38}{}}
\newlabel{eq:cnn}{{3.27}{39}{Convolutional Neural Networks (CNN)}{equation.3.6.27}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2.2}Attention Mechanism}{39}{subsubsection.3.6.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces An architecture of adding attention mechanism on top of the main layer with total time step of 4. The main layer is illustrated by the shaded architecture inside the rectangle. The main layer can be changed into any LSTM variant.\relax }}{40}{figure.caption.39}}
\newlabel{fig:dblstmhighwayattention}{{3.9}{40}{An architecture of adding attention mechanism on top of the main layer with total time step of 4. The main layer is illustrated by the shaded architecture inside the rectangle. The main layer can be changed into any LSTM variant.\relax }{figure.caption.39}{}}
\citation{seki2003probabilistic}
\newlabel{sum_weight}{{3.28}{41}{Attention Mechanism}{equation.3.6.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Experiment}{41}{section.3.7}}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}Evaluation}{41}{section.3.8}}
\@setckpt{bab3}{
\setcounter{page}{44}
\setcounter{equation}{35}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{8}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{9}
\setcounter{table}{5}
\setcounter{parentequation}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{0}
\setcounter{algocfproc}{0}
\setcounter{algocf}{0}
\setcounter{NAT@ctr}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{AM@survey}{0}
\setcounter{float@type}{8}
\setcounter{lstnumber}{1}
\setcounter{FancyVerbLine}{0}
\setcounter{Item}{44}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{52}
\setcounter{lstlisting}{0}
\setcounter{section@level}{1}
}
